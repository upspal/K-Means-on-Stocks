import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from datetime import date, timedelta

nifty50_tickers = [
    'RELIANCE.NS', 'HDFCBANK.NS', 'ICICIBANK.NS', 'INFY.NS', 'TCS.NS',
    'HINDUNILVR.NS', 'ITC.NS', 'SBIN.NS', 'BHARTIARTL.NS', 'KOTAKBANK.NS',
    'LT.NS', 'AXISBANK.NS', 'BAJFINANCE.NS', 'ASIANPAINT.NS', 'MARUTI.NS',
    'HCLTECH.NS', 'SUNPHARMA.NS', 'TITAN.NS', 'TATAMOTORS.NS', 'ULTRACEMCO.NS',
    'BAJAJFINSV.NS', 'WIPRO.NS', 'NTPC.NS', 'POWERGRID.NS', 'ADANIPORTS.NS',
    'JSWSTEEL.NS', 'TECHM.NS', 'ADANIENT.NS', 'TATASTEEL.NS', 'NESTLEIND.NS',
    'M&M.NS', 'ONGC.NS', 'GRASIM.NS', 'INDUSINDBK.NS', 'HINDALCO.NS',
    'CIPLA.NS', 'DRREDDY.NS', 'BAJAJ-AUTO.NS', 'COALINDIA.NS', 'EICHERMOT.NS',
    'SBILIFE.NS', 'HDFCLIFE.NS', 'BRITANNIA.NS', 'TATACONSUM.NS', 'APOLLOHOSP.NS',
    'HEROMOTOCO.NS', 'DIVISLAB.NS', 'UPL.NS', 'BPCL.NS', 'SHREECEM.NS'
]

def random_centroids(scaled_data, k):
    centroids = []
    for i in range(k):
        centroid = scaled_data.apply(lambda x: float(x.sample()))
        centroids.append(centroid)
    return pd.concat(centroids, axis=1)

def get_labels(scaled_data, centroids):
    distances = centroids.apply(lambda x: np.sqrt(((scaled_data - x) ** 2).sum(axis=1)))
    return distances.idxmin(axis=1)

def new_centroids(scaled_data, labels, k):
    centroids = scaled_data.groupby(labels).apply(lambda x: np.exp(np.log(x).mean())).T
    return centroids

def plot_clusters(scaled_data, labels, centroids, iteration):
    pca = PCA(n_components=2)
    data_2d = pca.fit_transform(scaled_data)
    centroids_2d = pca.transform(centroids.T)
    plt.title("Iteration: {}".format(iteration))
    scatter = plt.scatter(data_2d[:, 0], data_2d[:, 1], c=labels, cmap='viridis')
    plt.scatter(centroids_2d[:, 0], centroids_2d[:, 1], c='red', s=50, label='Centroids')
    unique_labels = sorted(set(labels))
    legend_elements = []
    for idx, label in enumerate(unique_labels):
        mask = (labels == label)
        if any(mask):
            color = scatter.to_rgba(label)  # Get exact color used for this label
            legend_elements.append(plt.scatter([], [], c=[color], label=f'Cluster {idx+1}'))
    # Add centroids to legend and display
    plt.legend(handles=legend_elements + [plt.scatter([], [], c='red', s=50, label='Centroids')])
    st.pyplot(plt)

def KMeansClustering(scaled_data, k):
    centroids = random_centroids(scaled_data, k)
    old_centroids = pd.DataFrame() 
    iteration = 1
    max_iterations = 100

    while iteration < max_iterations and not centroids.equals(old_centroids):
        old_centroids = centroids
        labels = get_labels(scaled_data, centroids)
        centroids = new_centroids(scaled_data,labels,k)
        iteration += 1
    plot_clusters(scaled_data, labels, centroids, iteration)
    # Map cluster labels to 1-based sequential numbers
    unique_labels = sorted(set(labels))
    label_mapping = {old: new+1 for new, old in enumerate(unique_labels)}
    mapped_labels = labels.map(label_mapping)
    scaled_data = pd.concat([scaled_data, pd.Series(mapped_labels, name='Cluster')], axis=1)
    return scaled_data

def main():
    st.set_page_config(
    page_title="K-Means Clustering for Stocks",
    page_icon="ðŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded")

    st.title("K-Means Clustering for Stocks")
    st.sidebar.title("ðŸ“ˆ K-Means Clustering for Stocks")
    st.sidebar.write("Created by")
    linkedin = "https://www.linkedin.com/in/pranavuppall"
    st.sidebar.markdown(f'<a href="{linkedin}" target="_blank" style="text-decoration: none; color: inherit;"><img src="https://cdn-icons-png.flaticon.com/512/174/174857.png" width="25" height="25" style="vertical-align: middle; margin-right: 10px;">`Pranav Uppal`</a>', unsafe_allow_html=True)

    # Clustering Parameters
    st.sidebar.header("Clustering Parameters")
    k = st.sidebar.slider("Number of Clusters (k)", min_value=2, max_value=10, value=4)
    timeframe_start = st.sidebar.date_input("Timeframe (Start)", pd.to_datetime("2020-01-01"), max_value=pd.to_datetime(date.today() - timedelta(days=-1)))
    timeframe_end = st.sidebar.date_input("Timeframe(End)", pd.to_datetime("2021-01-01"), max_value=pd.to_datetime(date.today()))

    # Stock Selection
    st.sidebar.header("Stock Selection")
    custom_ticker = st.sidebar.text_input("Enter Custom Ticker (separated by space):")
    select_all = st.sidebar.checkbox("Select All Stocks",value=True)
    selected_stocks = []
    if select_all:
        selected_stocks = nifty50_tickers
    else:
        selected_stocks = st.sidebar.multiselect("Select Stock", nifty50_tickers)
    if custom_ticker:
        custom_stocks = [stock.strip() for stock in custom_ticker.split(' ')]
        selected_stocks.extend(custom_stocks)

    if not selected_stocks:
        st.warning("Please select at least one stock to proceed.")
        return
    
    st.sidebar.header("Rerun Clustering")
    st.sidebar.write("The clustering can generate different results per run as each iteration reaches a local minimum!")
    if st.sidebar.button("Rerun"):
        st.cache_data.clear()

    # Data Fetching and Preprocessing
    try:
        if timeframe_start == timeframe_end:
            st.error("Start and end dates are the same. Please select different dates.")
            return
        
        data = yf.download(selected_stocks, start=timeframe_start, end=timeframe_end)
        
        if data.empty:
            st.error("No data found for the selected stocks. Please check if the stock symbols are correct.")
            return
            
        returns = data['Adj Close'].pct_change()
        returns = returns.iloc[1:]
        returns = returns.dropna(axis=1)
        
        if returns.empty:
            st.error("No valid return data available for the selected stocks and timeframe.")
            return

        if len(returns.columns) < k:
            st.error(f"Number of valid stocks ({len(returns.columns)}) is less than the number of clusters ({k}). Please select more stocks or reduce the number of clusters.")
            return

        features = ["Mean Returns", "Volatility", "Sharpe Ratio"]
        cluster_data = pd.DataFrame(index=returns.columns, columns=features)
        cluster_data["Mean Returns"] = returns.mean()
        cluster_data["Volatility"] = returns.std()
        cluster_data["Sharpe Ratio"] = cluster_data["Mean Returns"] / cluster_data["Volatility"]

        cluster_data = cluster_data.dropna(subset=features)

        scaled_data = ((cluster_data - cluster_data.min()) / (cluster_data.max() - cluster_data.min())) * 9 + 1

        col1, col2 = st.columns(2)
        with col1:
            st.header("Clustered Stock Returns")
            rawdataset = KMeansClustering(scaled_data, k)
            dataset=rawdataset.dropna(subset=['Cluster'])

        with col2:
            st.header("Clustered Stock Returns Data")
            dataset=cluster_data.join(dataset['Cluster']) 
            st.write(dataset)
        
        st.header("Cluster Summary")
        
        summary_data = pd.DataFrame(columns=["Cluster", "Average Returns", "Volatility", "Sharpe Ratio"])
        for cluster in dataset['Cluster'].unique():
            cluster_data = dataset[dataset['Cluster'] == cluster]
            avg_returns = cluster_data['Mean Returns'].mean()
            volatility = cluster_data['Volatility'].mean()
            sharpe_ratio = cluster_data['Sharpe Ratio'].mean()
            summary_data = pd.concat([summary_data, pd.DataFrame({"Cluster": [cluster], "Average Returns": [avg_returns], "Volatility": [volatility], "Sharpe Ratio": [sharpe_ratio]})], ignore_index=True)
            summary_data = summary_data.sort_values("Cluster", ascending=True)
        # Display summary data using st.metric
        for index, row in summary_data.iterrows():
            st.header(f"Cluster {row['Cluster']}")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric(label="Average Returns", value=f"{row['Average Returns'] * 100:.2f}%")
            with col2:
                st.metric(label="Volatility", value=f"{row['Volatility']:.2f}")
            with col3:
                st.metric(label="Sharpe Ratio", value=f"{row['Sharpe Ratio']:.2f}")
            
    except Exception as e:
        st.error(f"An error occurred: {str(e)}")
        if "Invalid ticker" in str(e):
            st.error("One or more stock symbols are invalid. Please check your input.")

if __name__ == "__main__":
    main()
